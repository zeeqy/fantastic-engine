{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import spatial\n",
    "from util.util import mnist_noise\n",
    "\n",
    "from trajectoryReweight.model import WeightedCrossEntropyLoss, TrajectoryReweightNN\n",
    "from trajectoryReweight.baseline import StandardTrainingNN\n",
    "from trajectoryReweight.gmm import GaussianMixture\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN\n",
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "def accuracy(predict_y, test_y):\n",
    "    score = 0\n",
    "    for pred, acc in zip(predict_y, test_y):\n",
    "        if pred == acc:\n",
    "            score +=1\n",
    "    return score / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNIST DATA\n",
    "\"\"\"\n",
    "x_train = read_idx('data/train-images.idx3-ubyte')\n",
    "y_train = read_idx('data/train-labels.idx1-ubyte')\n",
    "x_test = read_idx('data/t10k-images.idx3-ubyte')\n",
    "y_test = read_idx('data/t10k-labels.idx1-ubyte')\n",
    "valid_idx = np.random.choice(range(60000), size=1000, replace=False)\n",
    "x_valid = x_train[valid_idx]\n",
    "y_valid = y_train[valid_idx]\n",
    "x_train = np.delete(x_train, valid_idx, axis=0)\n",
    "y_train = np.delete(y_train, valid_idx)\n",
    "\n",
    "\"\"\"\n",
    "shrink dataset to make noisy significant\n",
    "\"\"\"\n",
    "subset_idx = np.random.choice(range(60000-1000), size=10000, replace=False)\n",
    "x_train = x_train[subset_idx]\n",
    "y_train = y_train[subset_idx]\n",
    "\n",
    "\"\"\"\n",
    "Add Noise label to training data\n",
    "\"\"\"\n",
    "y_train_noisy, noise_index = mnist_noise(y_train,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializaion\n",
    "\"\"\"\n",
    "train_idx = np.arange(len(x_train))\n",
    "x_train = np.transpose(x_train,(2,1,0))\n",
    "x_valid = np.transpose(x_valid,(2,1,0))\n",
    "x_test = np.transpose(x_test,(2,1,0))\n",
    "x_train_tensor = torchvision.transforms.ToTensor()(x_train).unsqueeze(1)\n",
    "x_valid_tensor = torchvision.transforms.ToTensor()(x_valid).unsqueeze(1)\n",
    "x_test_tensor = torchvision.transforms.ToTensor()(x_test).unsqueeze(1)\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.long))\n",
    "y_train_noisy_tensor = torch.from_numpy(y_train_noisy.astype(np.long))\n",
    "y_valid_tensor = torch.from_numpy(y_valid.astype(np.long))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard NN training...\n",
      "epoch = 1 | training loss = 0.9581 | valid loss = 0.0049 | valid accuarcy = 96.5% | early stopping = 0/7 | test loss = 0.0046 | test accuarcy = 96.25% [9625/10000]\n",
      "epoch = 2 | training loss = 0.7433 | valid loss = 0.0048 | valid accuarcy = 97.3% | early stopping = 0/7 | test loss = 0.0044 | test accuarcy = 97.19% [9719/10000]\n",
      "epoch = 3 | training loss = 0.7087 | valid loss = 0.0049 | valid accuarcy = 96.6% | early stopping = 1/7 | test loss = 0.0045 | test accuarcy = 97.4% [9740/10000]\n",
      "epoch = 4 | training loss = 0.6796 | valid loss = 0.0036 | valid accuarcy = 96.5% | early stopping = 0/7 | test loss = 0.0030 | test accuarcy = 97.11% [9711/10000]\n",
      "epoch = 5 | training loss = 0.6595 | valid loss = 0.0028 | valid accuarcy = 98.5% | early stopping = 0/7 | test loss = 0.0025 | test accuarcy = 98.13% [9813/10000]\n",
      "epoch = 6 | training loss = 0.6398 | valid loss = 0.0028 | valid accuarcy = 98.7% | early stopping = 1/7 | test loss = 0.0026 | test accuarcy = 98.3% [9830/10000]\n",
      "epoch = 7 | training loss = 0.6194 | valid loss = 0.0030 | valid accuarcy = 98.0% | early stopping = 2/7 | test loss = 0.0028 | test accuarcy = 98.39% [9839/10000]\n",
      "epoch = 8 | training loss = 0.6144 | valid loss = 0.0032 | valid accuarcy = 98.1% | early stopping = 3/7 | test loss = 0.0029 | test accuarcy = 98.18% [9818/10000]\n",
      "epoch = 9 | training loss = 0.5913 | valid loss = 0.0031 | valid accuarcy = 98.5% | early stopping = 4/7 | test loss = 0.0028 | test accuarcy = 98.26% [9826/10000]\n",
      "epoch = 10 | training loss = 0.5760 | valid loss = 0.0033 | valid accuarcy = 98.0% | early stopping = 5/7 | test loss = 0.0030 | test accuarcy = 98.05% [9805/10000]\n",
      "epoch = 11 | training loss = 0.5696 | valid loss = 0.0028 | valid accuarcy = 98.1% | early stopping = 6/7 | test loss = 0.0026 | test accuarcy = 98.17% [9817/10000]\n",
      "epoch = 12 | training loss = 0.5599 | valid loss = 0.0030 | valid accuarcy = 98.2% | early stopping = 7/7 | test loss = 0.0028 | test accuarcy = 98.36% [9836/10000]\n",
      "Standard training complete, best validation loss = 0.002755269892513752 at epoch = 5.\n",
      "test accuracy is 98.13%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN without reweight\n",
    "\"\"\"\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "\n",
    "stand_trainNN = StandardTrainingNN(cnn,\n",
    "                                   batch_size=64,\n",
    "                                   num_iter=80,\n",
    "                                   learning_rate=1e-3,\n",
    "                                   early_stopping=7,\n",
    "                                   device=device,\n",
    "                                   iprint=1)\n",
    "stand_trainNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor, x_test_tensor, y_test_tensor)\n",
    "\n",
    "test_output_y = stand_trainNN.predict(x_test_tensor)\n",
    "test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "\n",
    "print('test accuracy is {}%'.format(100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 3 burn-in epoch...\n",
      "epoch = 1 | test loss = 0.0059 | test accuarcy = 92.05% [9205/10000]\n",
      "epoch = 2 | test loss = 0.0058 | test accuarcy = 95.57% [9557/10000]\n",
      "epoch = 3 | test loss = 0.0051 | test accuarcy = 95.58% [9558/10000]\n",
      "Train 3 burn-in epoch complete.\n",
      "------------------------------------------------------------\n",
      "Trajectory clustering for burn-in epoch...\n",
      "| - {0: 0, 'size': 925, 'sim': '0.9868', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 1756, 'sim': '0.9940', 'num_special': 1, 'spe_ratio': '0.0006'}\n",
      "| - {2: 2, 'size': 903, 'sim': '0.9917', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 1118, 'sim': '0.9893', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1170, 'sim': '0.9941', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 636, 'sim': '0.9929', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 519, 'sim': '0.9916', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1018, 'sim': '0.3957', 'num_special': 948, 'spe_ratio': '0.9312'}\n",
      "| - {8: 8, 'size': 649, 'sim': '0.5461', 'num_special': 51, 'spe_ratio': '0.0786'}\n",
      "| - {9: 9, 'size': 1306, 'sim': '0.7409', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "Trajectory clustering for burn-in epoch complete.\n",
      "------------------------------------------------------------\n",
      "Trajectory based training start ...\n",
      "\n",
      "epoch = 4 | training loss = 0.7478 | valid loss = 0.0041 | valid accuarcy = 97.1% | early stopping = 0/7 | test loss = 0.0038 | test accuarcy = 96.68% [9668/10000]\n",
      "| - {0: 0, 'size': 886, 'sim': '0.9679', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 1341, 'sim': '0.9168', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 1232, 'sim': '0.9883', 'num_special': 4, 'spe_ratio': '0.0032'}\n",
      "| - {3: 3, 'size': 1052, 'sim': '0.9926', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1581, 'sim': '0.9896', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 413, 'sim': '0.9911', 'num_special': 51, 'spe_ratio': '0.1235'}\n",
      "| - {6: 6, 'size': 1001, 'sim': '-0.0048', 'num_special': 945, 'spe_ratio': '0.9441'}\n",
      "| - {7: 7, 'size': 656, 'sim': '0.0417', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 894, 'sim': '0.1249', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 944, 'sim': '0.3802', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 5 | training loss = 0.7426 | valid loss = 0.0029 | valid accuarcy = 97.7% | early stopping = 0/7 | test loss = 0.0026 | test accuarcy = 97.68% [9768/10000]\n",
      "| - {0: 0, 'size': 1205, 'sim': '0.9838', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 1169, 'sim': '0.9746', 'num_special': 1, 'spe_ratio': '0.0009'}\n",
      "| - {2: 2, 'size': 1280, 'sim': '0.9529', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 1072, 'sim': '0.9848', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 637, 'sim': '0.9856', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 988, 'sim': '-0.7166', 'num_special': 950, 'spe_ratio': '0.9615'}\n",
      "| - {6: 6, 'size': 602, 'sim': '-0.7139', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1539, 'sim': '-0.6282', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 421, 'sim': '-0.5050', 'num_special': 49, 'spe_ratio': '0.1164'}\n",
      "| - {9: 9, 'size': 1087, 'sim': '-0.4517', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 6 | training loss = 0.7076 | valid loss = 0.0035 | valid accuarcy = 97.7% | early stopping = 1/7 | test loss = 0.0032 | test accuarcy = 97.84% [9784/10000]\n",
      "| - {0: 0, 'size': 260, 'sim': '0.6374', 'num_special': 61, 'spe_ratio': '0.2346'}\n",
      "| - {1: 1, 'size': 1347, 'sim': '0.8951', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 665, 'sim': '0.9299', 'num_special': 1, 'spe_ratio': '0.0015'}\n",
      "| - {3: 3, 'size': 941, 'sim': '0.9596', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1816, 'sim': '0.9760', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1325, 'sim': '0.9821', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1289, 'sim': '0.9867', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 718, 'sim': '0.9890', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 965, 'sim': '0.1038', 'num_special': 938, 'spe_ratio': '0.9720'}\n",
      "| - {9: 9, 'size': 674, 'sim': '0.1756', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 7 | training loss = 0.7155 | valid loss = 0.0033 | valid accuarcy = 98.3% | early stopping = 2/7 | test loss = 0.0030 | test accuarcy = 97.84% [9784/10000]\n",
      "| - {0: 0, 'size': 749, 'sim': '0.9169', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 1442, 'sim': '0.9506', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 419, 'sim': '0.9407', 'num_special': 59, 'spe_ratio': '0.1408'}\n",
      "| - {3: 3, 'size': 790, 'sim': '0.9513', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1476, 'sim': '0.9830', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1642, 'sim': '0.9906', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1325, 'sim': '0.9839', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1193, 'sim': '0.9901', 'num_special': 1, 'spe_ratio': '0.0008'}\n",
      "| - {8: 8, 'size': 424, 'sim': '0.3741', 'num_special': 402, 'spe_ratio': '0.9481'}\n",
      "| - {9: 9, 'size': 540, 'sim': '-0.7278', 'num_special': 538, 'spe_ratio': '0.9963'}\n",
      "epoch = 8 | training loss = 0.7006 | valid loss = 0.0032 | valid accuarcy = 98.2% | early stopping = 3/7 | test loss = 0.0029 | test accuarcy = 98.24% [9824/10000]\n",
      "| - {0: 0, 'size': 286, 'sim': '0.7931', 'num_special': 57, 'spe_ratio': '0.1993'}\n",
      "| - {1: 1, 'size': 1575, 'sim': '0.9036', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 411, 'sim': '-0.9351', 'num_special': 395, 'spe_ratio': '0.9611'}\n",
      "| - {3: 3, 'size': 723, 'sim': '-0.9305', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1841, 'sim': '-0.9049', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1509, 'sim': '-0.8862', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1391, 'sim': '-0.7629', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 979, 'sim': '-0.4507', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 736, 'sim': '0.3299', 'num_special': 1, 'spe_ratio': '0.0014'}\n",
      "| - {9: 9, 'size': 549, 'sim': '-0.9398', 'num_special': 547, 'spe_ratio': '0.9964'}\n",
      "epoch = 9 | training loss = 0.6635 | valid loss = 0.0030 | valid accuarcy = 98.3% | early stopping = 4/7 | test loss = 0.0028 | test accuarcy = 97.93% [9793/10000]\n",
      "| - {0: 0, 'size': 395, 'sim': '-0.8057', 'num_special': 381, 'spe_ratio': '0.9646'}\n",
      "| - {1: 1, 'size': 1001, 'sim': '-0.6910', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {2: 2, 'size': 1684, 'sim': '-0.5587', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 946, 'sim': '-0.5063', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1235, 'sim': '-0.1883', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 568, 'sim': '-0.7610', 'num_special': 566, 'spe_ratio': '0.9965'}\n",
      "| - {6: 6, 'size': 373, 'sim': '-0.7242', 'num_special': 52, 'spe_ratio': '0.1394'}\n",
      "| - {7: 7, 'size': 1319, 'sim': '-0.6901', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 1017, 'sim': '-0.6883', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 1462, 'sim': '-0.6812', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 10 | training loss = 0.6310 | valid loss = 0.0026 | valid accuarcy = 98.3% | early stopping = 0/7 | test loss = 0.0023 | test accuarcy = 98.12% [9812/10000]\n",
      "| - {0: 0, 'size': 598, 'sim': '-0.8745', 'num_special': 594, 'spe_ratio': '0.9933'}\n",
      "| - {1: 1, 'size': 1189, 'sim': '-0.8712', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 369, 'sim': '-0.8694', 'num_special': 357, 'spe_ratio': '0.9675'}\n",
      "| - {3: 3, 'size': 1729, 'sim': '-0.8583', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 891, 'sim': '-0.8570', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1101, 'sim': '-0.8486', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1138, 'sim': '-0.8456', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 405, 'sim': '-0.8093', 'num_special': 48, 'spe_ratio': '0.1185'}\n",
      "| - {8: 8, 'size': 1577, 'sim': '-0.8013', 'num_special': 0, 'spe_ratio': '0.0000'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| - {9: 9, 'size': 1003, 'sim': '-0.7665', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "epoch = 11 | training loss = 0.5957 | valid loss = 0.0029 | valid accuarcy = 98.0% | early stopping = 1/7 | test loss = 0.0026 | test accuarcy = 98.13% [9813/10000]\n",
      "| - {0: 0, 'size': 1137, 'sim': '0.9827', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 358, 'sim': '-0.8404', 'num_special': 347, 'spe_ratio': '0.9693'}\n",
      "| - {2: 2, 'size': 388, 'sim': '-0.7499', 'num_special': 48, 'spe_ratio': '0.1237'}\n",
      "| - {3: 3, 'size': 1210, 'sim': '-0.6624', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 609, 'sim': '-0.8450', 'num_special': 604, 'spe_ratio': '0.9918'}\n",
      "| - {5: 5, 'size': 1724, 'sim': '-0.8273', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1496, 'sim': '-0.8256', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 892, 'sim': '-0.8154', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 985, 'sim': '-0.7707', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {9: 9, 'size': 1201, 'sim': '-0.7033', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 12 | training loss = 0.5649 | valid loss = 0.0026 | valid accuarcy = 98.3% | early stopping = 2/7 | test loss = 0.0023 | test accuarcy = 98.33% [9833/10000]\n",
      "| - {0: 0, 'size': 1502, 'sim': '0.9748', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 394, 'sim': '0.9504', 'num_special': 47, 'spe_ratio': '0.1193'}\n",
      "| - {2: 2, 'size': 989, 'sim': '0.9785', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {3: 3, 'size': 618, 'sim': '-0.9284', 'num_special': 614, 'spe_ratio': '0.9935'}\n",
      "| - {4: 4, 'size': 1184, 'sim': '-0.9283', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1229, 'sim': '-0.8856', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 861, 'sim': '-0.8738', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1123, 'sim': '-0.8267', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 1750, 'sim': '-0.7521', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 350, 'sim': '-0.8925', 'num_special': 338, 'spe_ratio': '0.9657'}\n",
      "epoch = 13 | training loss = 0.5375 | valid loss = 0.0025 | valid accuarcy = 98.6% | early stopping = 0/7 | test loss = 0.0022 | test accuarcy = 98.43% [9843/10000]\n",
      "| - {0: 0, 'size': 970, 'sim': '0.9882', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 620, 'sim': '-0.9746', 'num_special': 617, 'spe_ratio': '0.9952'}\n",
      "| - {2: 2, 'size': 345, 'sim': '-0.9752', 'num_special': 333, 'spe_ratio': '0.9652'}\n",
      "| - {3: 3, 'size': 1457, 'sim': '-0.9753', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 394, 'sim': '-0.9723', 'num_special': 49, 'spe_ratio': '0.1244'}\n",
      "| - {5: 5, 'size': 813, 'sim': '-0.9716', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1637, 'sim': '-0.9683', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1435, 'sim': '-0.9672', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 947, 'sim': '-0.9594', 'num_special': 1, 'spe_ratio': '0.0011'}\n",
      "| - {9: 9, 'size': 1382, 'sim': '-0.9544', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 14 | training loss = 0.4972 | valid loss = 0.0020 | valid accuarcy = 98.6% | early stopping = 0/7 | test loss = 0.0018 | test accuarcy = 98.29% [9829/10000]\n",
      "| - {0: 0, 'size': 396, 'sim': '0.8102', 'num_special': 47, 'spe_ratio': '0.1187'}\n",
      "| - {1: 1, 'size': 344, 'sim': '-0.9304', 'num_special': 333, 'spe_ratio': '0.9680'}\n",
      "| - {2: 2, 'size': 1018, 'sim': '-0.9080', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {3: 3, 'size': 809, 'sim': '-0.9054', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1363, 'sim': '-0.8875', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 931, 'sim': '-0.8794', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1386, 'sim': '-0.8735', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1717, 'sim': '-0.8414', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 620, 'sim': '-0.9548', 'num_special': 619, 'spe_ratio': '0.9984'}\n",
      "| - {9: 9, 'size': 1416, 'sim': '-0.9541', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 15 | training loss = 0.4615 | valid loss = 0.0021 | valid accuarcy = 98.3% | early stopping = 1/7 | test loss = 0.0019 | test accuarcy = 98.38% [9838/10000]\n",
      "| - {0: 0, 'size': 999, 'sim': '0.9901', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 906, 'sim': '0.9936', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 1598, 'sim': '0.9895', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 1315, 'sim': '0.9925', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 995, 'sim': '0.9909', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {5: 5, 'size': 400, 'sim': '0.9814', 'num_special': 46, 'spe_ratio': '0.1150'}\n",
      "| - {6: 6, 'size': 340, 'sim': '-0.8468', 'num_special': 329, 'spe_ratio': '0.9676'}\n",
      "| - {7: 7, 'size': 1414, 'sim': '-0.8306', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 1407, 'sim': '-0.7797', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 626, 'sim': '-0.9481', 'num_special': 624, 'spe_ratio': '0.9968'}\n",
      "epoch = 16 | training loss = 0.4437 | valid loss = 0.0024 | valid accuarcy = 98.2% | early stopping = 2/7 | test loss = 0.0021 | test accuarcy = 98.57% [9857/10000]\n",
      "| - {0: 0, 'size': 389, 'sim': '0.8962', 'num_special': 46, 'spe_ratio': '0.1183'}\n",
      "| - {1: 1, 'size': 336, 'sim': '-0.8832', 'num_special': 325, 'spe_ratio': '0.9673'}\n",
      "| - {2: 2, 'size': 819, 'sim': '-0.8793', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 1621, 'sim': '-0.8482', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1450, 'sim': '-0.8306', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1353, 'sim': '-0.8043', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 939, 'sim': '-0.7880', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1453, 'sim': '-0.7254', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 1010, 'sim': '-0.5272', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {9: 9, 'size': 630, 'sim': '-0.9117', 'num_special': 628, 'spe_ratio': '0.9968'}\n",
      "epoch = 17 | training loss = 0.4208 | valid loss = 0.0022 | valid accuarcy = 98.5% | early stopping = 3/7 | test loss = 0.0020 | test accuarcy = 98.62% [9862/10000]\n",
      "| - {0: 0, 'size': 329, 'sim': '-0.9565', 'num_special': 319, 'spe_ratio': '0.9696'}\n",
      "| - {1: 1, 'size': 1005, 'sim': '-0.9416', 'num_special': 1, 'spe_ratio': '0.0010'}\n",
      "| - {2: 2, 'size': 389, 'sim': '-0.9162', 'num_special': 46, 'spe_ratio': '0.1183'}\n",
      "| - {3: 3, 'size': 636, 'sim': '-0.9676', 'num_special': 634, 'spe_ratio': '0.9969'}\n",
      "| - {4: 4, 'size': 955, 'sim': '-0.9672', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1423, 'sim': '-0.9659', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1272, 'sim': '-0.9653', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1589, 'sim': '-0.9626', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 967, 'sim': '-0.9606', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 1435, 'sim': '-0.9567', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 18 | training loss = 0.3923 | valid loss = 0.0020 | valid accuarcy = 98.6% | early stopping = 0/7 | test loss = 0.0017 | test accuarcy = 98.36% [9836/10000]\n",
      "| - {0: 0, 'size': 1404, 'sim': '0.9939', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 343, 'sim': '-0.9469', 'num_special': 332, 'spe_ratio': '0.9679'}\n",
      "| - {2: 2, 'size': 357, 'sim': '-0.9241', 'num_special': 46, 'spe_ratio': '0.1289'}\n",
      "| - {3: 3, 'size': 1545, 'sim': '-0.9169', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 966, 'sim': '-0.9093', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 1717, 'sim': '-0.8992', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1190, 'sim': '-0.8937', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 621, 'sim': '-0.9590', 'num_special': 621, 'spe_ratio': '1.0000'}\n",
      "| - {8: 8, 'size': 959, 'sim': '-0.9585', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 898, 'sim': '-0.9531', 'num_special': 1, 'spe_ratio': '0.0011'}\n",
      "epoch = 19 | training loss = 0.3533 | valid loss = 0.0021 | valid accuarcy = 98.5% | early stopping = 1/7 | test loss = 0.0019 | test accuarcy = 98.4% [9840/10000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| - {0: 0, 'size': 353, 'sim': '0.9015', 'num_special': 46, 'spe_ratio': '0.1303'}\n",
      "| - {1: 1, 'size': 1783, 'sim': '0.9587', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 808, 'sim': '0.9623', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 899, 'sim': '0.9775', 'num_special': 1, 'spe_ratio': '0.0011'}\n",
      "| - {4: 4, 'size': 331, 'sim': '-0.8048', 'num_special': 322, 'spe_ratio': '0.9728'}\n",
      "| - {5: 5, 'size': 1644, 'sim': '-0.7732', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 1421, 'sim': '-0.6845', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {7: 7, 'size': 1020, 'sim': '-0.6678', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 1110, 'sim': '-0.6057', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 631, 'sim': '-0.9193', 'num_special': 631, 'spe_ratio': '1.0000'}\n",
      "epoch = 20 | training loss = 0.3304 | valid loss = 0.0018 | valid accuarcy = 98.3% | early stopping = 0/7 | test loss = 0.0015 | test accuarcy = 98.68% [9868/10000]\n",
      "| - {0: 0, 'size': 611, 'sim': '-0.9002', 'num_special': 611, 'spe_ratio': '1.0000'}\n",
      "| - {1: 1, 'size': 1114, 'sim': '-0.8935', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 886, 'sim': '-0.8778', 'num_special': 1, 'spe_ratio': '0.0011'}\n",
      "| - {3: 3, 'size': 1744, 'sim': '-0.8717', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1361, 'sim': '-0.8576', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 954, 'sim': '-0.8537', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {6: 6, 'size': 351, 'sim': '-0.7931', 'num_special': 41, 'spe_ratio': '0.1168'}\n",
      "| - {7: 7, 'size': 359, 'sim': '-0.8602', 'num_special': 347, 'spe_ratio': '0.9666'}\n",
      "| - {8: 8, 'size': 1004, 'sim': '-0.8604', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {9: 9, 'size': 1616, 'sim': '-0.8618', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 21 | training loss = 0.2975 | valid loss = 0.0017 | valid accuarcy = 98.6% | early stopping = 0/7 | test loss = 0.0015 | test accuarcy = 98.47% [9847/10000]\n",
      "| - {0: 0, 'size': 1355, 'sim': '0.9971', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {1: 1, 'size': 344, 'sim': '0.8741', 'num_special': 41, 'spe_ratio': '0.1192'}\n",
      "| - {2: 2, 'size': 1725, 'sim': '0.9286', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 1390, 'sim': '0.9594', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {4: 4, 'size': 1244, 'sim': '0.9661', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {5: 5, 'size': 609, 'sim': '-0.9185', 'num_special': 609, 'spe_ratio': '1.0000'}\n",
      "| - {6: 6, 'size': 360, 'sim': '-0.9448', 'num_special': 349, 'spe_ratio': '0.9694'}\n",
      "| - {7: 7, 'size': 795, 'sim': '-0.9445', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {8: 8, 'size': 911, 'sim': '-0.9383', 'num_special': 1, 'spe_ratio': '0.0011'}\n",
      "| - {9: 9, 'size': 1267, 'sim': '-0.9371', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "epoch = 22 | training loss = 0.2748 | valid loss = 0.0017 | valid accuarcy = 98.7% | early stopping = 0/7 | test loss = 0.0015 | test accuarcy = 98.61% [9861/10000]\n",
      "| - {0: 0, 'size': 610, 'sim': '-0.9531', 'num_special': 610, 'spe_ratio': '1.0000'}\n",
      "| - {1: 1, 'size': 358, 'sim': '-0.9538', 'num_special': 348, 'spe_ratio': '0.9721'}\n",
      "| - {2: 2, 'size': 912, 'sim': '-0.9538', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {3: 3, 'size': 790, 'sim': '-0.9479', 'num_special': 1, 'spe_ratio': '0.0013'}\n",
      "| - {4: 4, 'size': 1410, 'sim': '-0.9452', 'num_special': 0, 'spe_ratio': '0.0000'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN with reweight\n",
    "\"\"\"\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "\n",
    "tra_weightNN = TrajectoryReweightNN(cnn,\n",
    "                                    burnin=3,\n",
    "                                    num_cluster=10,\n",
    "                                    batch_size=64,\n",
    "                                    num_iter=80,\n",
    "                                    learning_rate=1e-3,\n",
    "                                    early_stopping=7,\n",
    "                                    device=device,\n",
    "                                    traj_step=1,\n",
    "                                    iprint=2)\n",
    "tra_weightNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor,x_test_tensor, y_test_tensor, noise_index)\n",
    "\n",
    "test_output_y = tra_weightNN.predict(x_test_tensor)\n",
    "test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "\n",
    "print('test accuracy is {}%'.format(100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Different noise level\n",
    "\"\"\"\n",
    "\n",
    "noise_level = [0.1,0.2,0.4,0.6,0.8]\n",
    "exp_summary = []\n",
    "\n",
    "for level in noise_level:\n",
    "    \n",
    "    level_summary = {\"noise_level\": level, \"std_test\":0, \"rewgt_test\":0}       \n",
    "        \n",
    "    np.random.seed(int(time.time()))\n",
    "    x_train = read_idx('data/train-images.idx3-ubyte')\n",
    "    y_train = read_idx('data/train-labels.idx1-ubyte')\n",
    "    x_test = read_idx('data/t10k-images.idx3-ubyte')\n",
    "    y_test = read_idx('data/t10k-labels.idx1-ubyte')\n",
    "    valid_idx = np.random.choice(range(60000), size=1000, replace=False)\n",
    "    x_valid = x_train[valid_idx]\n",
    "    y_valid = y_train[valid_idx]\n",
    "    x_train = np.delete(x_train, valid_idx, axis=0)\n",
    "    y_train = np.delete(y_train, valid_idx)\n",
    "\n",
    "    y_train_noisy = mnist_noise(y_train, level) #apply noise level\n",
    " \n",
    "    train_idx = np.arange(len(x_train))\n",
    "    x_train = np.transpose(x_train,(2,1,0))\n",
    "    x_valid = np.transpose(x_valid,(2,1,0))\n",
    "    x_test = np.transpose(x_test,(2,1,0))\n",
    "    x_train_tensor = torchvision.transforms.ToTensor()(x_train).unsqueeze(1)\n",
    "    x_valid_tensor = torchvision.transforms.ToTensor()(x_valid).unsqueeze(1)\n",
    "    x_test_tensor = torchvision.transforms.ToTensor()(x_test).unsqueeze(1)\n",
    "    y_train_tensor = torch.from_numpy(y_train.astype(np.long))\n",
    "    y_train_noisy_tensor = torch.from_numpy(y_train_noisy.astype(np.long))\n",
    "    y_valid_tensor = torch.from_numpy(y_valid.astype(np.long))\n",
    "    y_test_tensor = torch.from_numpy(y_test.astype(np.long))\n",
    "\n",
    "    cnn = CNN()\n",
    "    cnn.to(device)\n",
    "\n",
    "    stand_trainNN = StandardTrainingNN(cnn,\n",
    "                                       batch_size=64,\n",
    "                                       num_iter=80,\n",
    "                                       learning_rate=1e-3,\n",
    "                                       early_stopping=5,\n",
    "                                       device=device,\n",
    "                                       iprint=0)\n",
    "    stand_trainNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor, x_test_tensor, y_test_tensor)\n",
    "\n",
    "    test_output_y = stand_trainNN.predict(x_test_tensor)\n",
    "    test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "    level_summary['std_test'] = test_accuracy\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    cnn = CNN()\n",
    "    cnn.to(device)\n",
    "\n",
    "    tra_weightNN = TrajectoryReweightNN(cnn,\n",
    "                                        burnin=5,\n",
    "                                        num_cluster=5,\n",
    "                                        batch_size=64,\n",
    "                                        num_iter=80,\n",
    "                                        learning_rate=1e-3,\n",
    "                                        early_stopping=5,\n",
    "                                        device=device,\n",
    "                                        traj_step = 3,\n",
    "                                        iprint=0)\n",
    "    tra_weightNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor,x_test_tensor, y_test_tensor)\n",
    "\n",
    "    test_output_y = tra_weightNN.predict(x_test_tensor)\n",
    "    test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "    level_summary['rewgt_test'] = test_accuracy\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    exp_summary.append(level_summary)\n",
    "    print('nosie level = {} finished running'.format(level))\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_index == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
