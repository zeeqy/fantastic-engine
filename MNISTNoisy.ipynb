{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import spatial\n",
    "from util.util import mnist_noise\n",
    "\n",
    "from trajectoryReweight.model import WeightedCrossEntropyLoss, TrajectoryReweightNN\n",
    "from trajectoryReweight.baseline import StandardTrainingNN\n",
    "from trajectoryReweight.gmm import GaussianMixture\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN\n",
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "def accuracy(predict_y, test_y):\n",
    "    score = 0\n",
    "    for pred, acc in zip(predict_y, test_y):\n",
    "        if pred == acc:\n",
    "            score +=1\n",
    "    return score / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNIST DATA\n",
    "\"\"\"\n",
    "x_train = read_idx('data/train-images.idx3-ubyte')\n",
    "y_train = read_idx('data/train-labels.idx1-ubyte')\n",
    "x_test = read_idx('data/t10k-images.idx3-ubyte')\n",
    "y_test = read_idx('data/t10k-labels.idx1-ubyte')\n",
    "valid_idx = np.random.choice(range(60000), size=1000, replace=False)\n",
    "x_valid = x_train[valid_idx]\n",
    "y_valid = y_train[valid_idx]\n",
    "x_train = np.delete(x_train, valid_idx, axis=0)\n",
    "y_train = np.delete(y_train, valid_idx)\n",
    "\n",
    "\"\"\"\n",
    "shrink dataset to make noisy significant\n",
    "\"\"\"\n",
    "subset_idx = np.random.choice(range(60000-1000), size=10000, replace=False)\n",
    "x_train = x_train[subset_idx]\n",
    "y_train = y_train[subset_idx]\n",
    "\n",
    "\"\"\"\n",
    "Add Noise label to training data\n",
    "\"\"\"\n",
    "y_train_noisy = mnist_noise(y_train,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializaion\n",
    "\"\"\"\n",
    "train_idx = np.arange(len(x_train))\n",
    "x_train = np.transpose(x_train,(2,1,0))\n",
    "x_valid = np.transpose(x_valid,(2,1,0))\n",
    "x_test = np.transpose(x_test,(2,1,0))\n",
    "x_train_tensor = torchvision.transforms.ToTensor()(x_train).unsqueeze(1)\n",
    "x_valid_tensor = torchvision.transforms.ToTensor()(x_valid).unsqueeze(1)\n",
    "x_test_tensor = torchvision.transforms.ToTensor()(x_test).unsqueeze(1)\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.long))\n",
    "y_train_noisy_tensor = torch.from_numpy(y_train_noisy.astype(np.long))\n",
    "y_valid_tensor = torch.from_numpy(y_valid.astype(np.long))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN without reweight\n",
    "\"\"\"\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "\n",
    "stand_trainNN = StandardTrainingNN(cnn,\n",
    "                                   batch_size=64,\n",
    "                                   num_iter=80,\n",
    "                                   learning_rate=1e-3,\n",
    "                                   early_stopping=5,\n",
    "                                   device=device,\n",
    "                                   iprint=1)\n",
    "stand_trainNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor, x_test_tensor, y_test_tensor)\n",
    "\n",
    "test_output_y = stand_trainNN.predict(x_test_tensor)\n",
    "test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "\n",
    "print('test accuracy is {}%'.format(100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN with reweight\n",
    "\"\"\"\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "\n",
    "tra_weightNN = TrajectoryReweightNN(cnn,\n",
    "                                    burnin=5,\n",
    "                                    num_cluster=5,\n",
    "                                    batch_size=64,\n",
    "                                    num_iter=80,\n",
    "                                    learning_rate=1e-3,\n",
    "                                    early_stopping=5,\n",
    "                                    device=device,\n",
    "                                    traj_step = 3,\n",
    "                                    iprint=1)\n",
    "tra_weightNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor,x_test_tensor, y_test_tensor)\n",
    "\n",
    "test_output_y = tra_weightNN.predict(x_test_tensor)\n",
    "test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "\n",
    "print('test accuracy is {}%'.format(100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nosie level = 0.1 finished running\n",
      "nosie level = 0.2 finished running\n",
      "nosie level = 0.4 finished running\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Different noise level\n",
    "\"\"\"\n",
    "\n",
    "noise_level = [0.1,0.2,0.4,0.6,0.8]\n",
    "exp_summary = []\n",
    "\n",
    "for level in noise_level:\n",
    "    \n",
    "    level_summary = {\"noise_level\": level, \"std_test\":0, \"rewgt_test\":0}       \n",
    "        \n",
    "    np.random.seed(int(time.time()))\n",
    "    x_train = read_idx('data/train-images.idx3-ubyte')\n",
    "    y_train = read_idx('data/train-labels.idx1-ubyte')\n",
    "    x_test = read_idx('data/t10k-images.idx3-ubyte')\n",
    "    y_test = read_idx('data/t10k-labels.idx1-ubyte')\n",
    "    valid_idx = np.random.choice(range(60000), size=1000, replace=False)\n",
    "    x_valid = x_train[valid_idx]\n",
    "    y_valid = y_train[valid_idx]\n",
    "    x_train = np.delete(x_train, valid_idx, axis=0)\n",
    "    y_train = np.delete(y_train, valid_idx)\n",
    "\n",
    "    y_train_noisy = mnist_noise(y_train, level) #apply noise level\n",
    " \n",
    "    train_idx = np.arange(len(x_train))\n",
    "    x_train = np.transpose(x_train,(2,1,0))\n",
    "    x_valid = np.transpose(x_valid,(2,1,0))\n",
    "    x_test = np.transpose(x_test,(2,1,0))\n",
    "    x_train_tensor = torchvision.transforms.ToTensor()(x_train).unsqueeze(1)\n",
    "    x_valid_tensor = torchvision.transforms.ToTensor()(x_valid).unsqueeze(1)\n",
    "    x_test_tensor = torchvision.transforms.ToTensor()(x_test).unsqueeze(1)\n",
    "    y_train_tensor = torch.from_numpy(y_train.astype(np.long))\n",
    "    y_train_noisy_tensor = torch.from_numpy(y_train_noisy.astype(np.long))\n",
    "    y_valid_tensor = torch.from_numpy(y_valid.astype(np.long))\n",
    "    y_test_tensor = torch.from_numpy(y_test.astype(np.long))\n",
    "\n",
    "    cnn = CNN()\n",
    "    cnn.to(device)\n",
    "\n",
    "    stand_trainNN = StandardTrainingNN(cnn,\n",
    "                                       batch_size=64,\n",
    "                                       num_iter=80,\n",
    "                                       learning_rate=1e-3,\n",
    "                                       early_stopping=5,\n",
    "                                       device=device,\n",
    "                                       iprint=0)\n",
    "    stand_trainNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor, x_test_tensor, y_test_tensor)\n",
    "\n",
    "    test_output_y = stand_trainNN.predict(x_test_tensor)\n",
    "    test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "    level_summary['std_test'] = test_accuracy\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    cnn = CNN()\n",
    "    cnn.to(device)\n",
    "\n",
    "    tra_weightNN = TrajectoryReweightNN(cnn,\n",
    "                                        burnin=5,\n",
    "                                        num_cluster=5,\n",
    "                                        batch_size=64,\n",
    "                                        num_iter=80,\n",
    "                                        learning_rate=1e-3,\n",
    "                                        early_stopping=5,\n",
    "                                        device=device,\n",
    "                                        traj_step = 3,\n",
    "                                        iprint=0)\n",
    "    tra_weightNN.fit(x_train_tensor, y_train_noisy_tensor, x_valid_tensor, y_valid_tensor,x_test_tensor, y_test_tensor)\n",
    "\n",
    "    test_output_y = tra_weightNN.predict(x_test_tensor)\n",
    "    test_accuracy = accuracy(test_output_y, y_test_tensor.data.numpy())\n",
    "    level_summary['rewgt_test'] = test_accuracy\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    exp_summary.append(level_summary)\n",
    "    print('nosie level = {} finished running'.format(level))\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
