{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json, time, sys\n",
    "import copy\n",
    "\n",
    "from networks import *\n",
    "\n",
    "from trajectoryPlugin.plugin import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, device, optimizer, api, reweight=False):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target, weight) in enumerate(api.train_loader):\n",
    "        data, target, weight = data.to(device), target.to(device), weight.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        if reweight:\n",
    "            loss = api.loss_func(output, target, weight, 'mean')\n",
    "        else:\n",
    "            loss = api.loss_func(output, target, None, 'mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def forward_fn(model, device, api, forward_type, test_loader=None):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    if forward_type == 'test':\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss += api.loss_func(output, target, None, 'sum').item() # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    elif forward_type == 'train':\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target, weight) in enumerate(api.train_loader):\n",
    "                data, target, weight = data.to(device), target.to(device), weight.to(device)\n",
    "                output = model(data)\n",
    "                loss += api.loss_func(output, target, weight, 'sum').item() # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(api.train_loader.dataset)\n",
    "        accuracy = 100. * correct / len(api.train_loader.dataset)\n",
    "\n",
    "    elif forward_type == 'validation':\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(api.valid_loader): \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss += api.loss_func(output, target, None, 'sum').item() # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(api.valid_loader.dataset)\n",
    "        accuracy = 100. * correct / len(api.valid_loader.dataset)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mnistdata = datasets.MNIST('../data', train=True, download=True,\n",
    "             transform=transforms.Compose([\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "             ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=100, shuffle=True)\n",
    "\n",
    "valid_index = np.random.choice(range(len(mnistdata)), size=5000, replace=False).tolist()\n",
    "train_index = np.delete(range(len(mnistdata)), valid_index).tolist()\n",
    "trainset = torch.utils.data.dataset.Subset(mnistdata, train_index)\n",
    "validset = torch.utils.data.dataset.Subset(mnistdata, valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "api = API(num_cluster=10, device=device, update_rate=1.0, iprint=2)\n",
    "api.dataLoader(trainset, validset, batch_size=100)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 4):\n",
    "\n",
    "    scheduler.step()\n",
    "    train_fn(model, device, optimizer, api, False)\n",
    "    api.createTrajectory(model)\n",
    "\n",
    "    loss, accuracy = forward_fn(model, device, api, 'train')\n",
    "\n",
    "\n",
    "    loss, accuracy = forward_fn(model, device, api, 'validation')\n",
    "\n",
    "\n",
    "    loss, accuracy = forward_fn(model, device, api, 'test', test_loader)\n",
    "\n",
    "\n",
    "    api.generateTrainLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 01:02:27,783 - INFO - | - {0: 0, 'size': 32869, 'sim': 0.27591025829315186}\n",
      "2019-05-11 01:02:27,794 - INFO - | - {1: 1, 'size': 1230, 'sim': 0.6549217104911804}\n",
      "2019-05-11 01:02:27,795 - INFO - | - {2: 2, 'size': 359, 'sim': 0.8191350102424622}\n",
      "2019-05-11 01:02:27,796 - INFO - | - {3: 3, 'size': 8518, 'sim': 0.3106919825077057}\n",
      "2019-05-11 01:02:27,797 - INFO - | - {4: 4, 'size': 1609, 'sim': 0.08273454755544662}\n",
      "2019-05-11 01:02:27,798 - INFO - | - {5: 5, 'size': 2309, 'sim': 0.7254108786582947}\n",
      "2019-05-11 01:02:27,798 - INFO - | - {6: 6, 'size': 1210, 'sim': 0.9206570386886597}\n",
      "2019-05-11 01:02:27,799 - INFO - | - {7: 7, 'size': 3484, 'sim': 0.1655312031507492}\n",
      "2019-05-11 01:02:27,800 - INFO - | - {8: 8, 'size': 1786, 'sim': 0.18751145899295807}\n",
      "2019-05-11 01:02:27,801 - INFO - | - {9: 9, 'size': 1626, 'sim': 0.6052157878875732}\n"
     ]
    }
   ],
   "source": [
    "api.trajectoryBins()\n",
    "api.clusterBins()\n",
    "api.reweightData(model, [])\n",
    "api.generateTrainLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2759)\n",
      "tensor(0.8606)\n",
      "0\n",
      "((tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242,  0.2249,  1.5996,  2.7960,  1.5996,  0.2122, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.1867,  2.6051,  2.7833,  2.7833,  2.7833,  2.5924, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.2631,\n",
      "           2.4651,  2.7960,  2.7833,  2.6178,  2.5415,  2.7833,  0.3013,\n",
      "          -0.3478, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.2969,  0.3395,  2.4269,\n",
      "           2.7833,  2.7960,  2.7833,  2.1469,  0.6450,  2.7833,  2.7960,\n",
      "           1.1286, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242,  1.6505,  2.7833,  2.7833,\n",
      "           2.7833,  2.7960,  2.7833,  2.7833,  0.7977,  1.9814,  2.7960,\n",
      "           1.7014, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242,  0.2249,  2.6051,  2.7960,  2.7960,\n",
      "           1.9942,  1.0268,  2.7960,  2.4778,  0.1740,  0.5813,  2.8215,\n",
      "           1.7141, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  0.1867,  2.6051,  2.7833,  2.7833,  1.8541,\n",
      "          -0.2715,  0.5304,  1.1159, -0.1569, -0.4242, -0.4242,  2.7960,\n",
      "           2.6687,  0.2122, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242,  0.0595,  1.6759,  2.7960,  2.5415,  2.2233,  0.6450,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
      "           2.7833,  1.6759, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.3351,  1.8414,  2.7833,  2.6306,  0.4795, -0.1824, -0.0678,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
      "           2.7833,  2.0578, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.3013,  2.7833,  2.7833,  0.3777, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
      "           2.7833,  2.0578, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           2.0960,  2.7960,  1.9942, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.8215,\n",
      "           2.7960,  2.0705, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.5431,\n",
      "           2.7069,  2.7833,  1.0013, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
      "           2.7833,  1.4596, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
      "           2.7833,  2.5033, -0.1060, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.3351,  1.2941,  2.7960,\n",
      "           1.9432, -0.2715, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
      "           2.7833,  2.4142, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.3351,  1.2432,  2.7833,  2.4396,\n",
      "           0.4795, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
      "           2.7833,  1.4214, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  0.1867,  1.6759,  2.7833,  1.7778, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6704,\n",
      "           2.7960,  2.4396, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242,  1.0268,  2.6051,  2.7960,  1.6378, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
      "           2.7833,  2.7451,  1.4341,  0.1867, -0.0551,  0.6577,  1.8414,\n",
      "           2.4396,  2.7960,  2.4142,  1.7014,  0.2886, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
      "           2.7833,  2.7833,  2.7833,  2.4906,  2.3124,  2.7833,  2.7833,\n",
      "           2.7833,  2.0705,  1.2305, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.0678,\n",
      "           2.1087,  2.7833,  2.7833,  2.7960,  2.7833,  2.7833,  2.5415,\n",
      "           1.4214, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.1060,  1.2050,  2.7833,  2.7960,  2.7833,  1.3705,  0.0467,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]), 0), (tensor(0.8606),))\n"
     ]
    }
   ],
   "source": [
    "print(api.weight_raw[1])\n",
    "print(api.weight_tensor[1])\n",
    "print(api.cluster_output[1])\n",
    "print(api.train_loader.dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
