{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from util.util import mnist_noise\n",
    "from copy import deepcopy\n",
    "from scipy import spatial\n",
    "\n",
    "from trajectoryPlugin.plugin import API\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN\n",
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        #self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "def accuracy(predict_y, test_y):\n",
    "    score = 0\n",
    "    for pred, acc in zip(predict_y, test_y):\n",
    "        if pred == acc:\n",
    "            score +=1\n",
    "    return score / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNIST DATA\n",
    "\"\"\"\n",
    "x_train = read_idx('data/train-images.idx3-ubyte')\n",
    "y_train = read_idx('data/train-labels.idx1-ubyte')\n",
    "x_test = read_idx('data/t10k-images.idx3-ubyte')\n",
    "y_test = read_idx('data/t10k-labels.idx1-ubyte')\n",
    "valid_idx = np.random.choice(range(60000), size=1000, replace=False)\n",
    "x_valid = x_train[valid_idx]\n",
    "y_valid = y_train[valid_idx]\n",
    "x_train = np.delete(x_train, valid_idx, axis=0)\n",
    "y_train = np.delete(y_train, valid_idx)\n",
    "\n",
    "\"\"\"\n",
    "shrink dataset to make noisy significant\n",
    "\"\"\"\n",
    "subset_idx = np.random.choice(range(60000-1000), size=10000, replace=False)\n",
    "x_train = x_train[subset_idx]\n",
    "y_train = y_train[subset_idx]\n",
    "\n",
    "\"\"\"\n",
    "Add Noise label to training data\n",
    "\"\"\"\n",
    "y_train_noisy, noise_index = mnist_noise(y_train,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializaion\n",
    "\"\"\"\n",
    "train_idx = np.arange(len(x_train))\n",
    "x_train = np.transpose(x_train,(2,1,0))\n",
    "x_valid = np.transpose(x_valid,(2,1,0))\n",
    "x_test = np.transpose(x_test,(2,1,0))\n",
    "x_train_tensor = torchvision.transforms.ToTensor()(x_train).unsqueeze(1)\n",
    "x_valid_tensor = torchvision.transforms.ToTensor()(x_valid).unsqueeze(1)\n",
    "x_test_tensor = torchvision.transforms.ToTensor()(x_test).unsqueeze(1)\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.long))\n",
    "y_train_noisy_tensor = torch.from_numpy(y_train_noisy.astype(np.long))\n",
    "y_valid_tensor = torch.from_numpy(y_valid.astype(np.long))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================epoch = 1====================\n",
      "====================epoch = 2====================\n",
      "====================epoch = 3====================\n",
      "====================epoch = 4====================\n",
      "====================epoch = 5====================\n",
      "====================epoch = 6====================\n",
      "| - {0: 0, 'size': 944, 'sim': '-0.9287', 'num_special': 933, 'spe_ratio': '0.9883'}\n",
      "| - {1: 1, 'size': 6069, 'sim': '0.9659', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 2987, 'sim': '0.9635', 'num_special': 67, 'spe_ratio': '0.0224'}\n",
      "====================epoch = 7====================\n",
      "| - {0: 0, 'size': 942, 'sim': '-0.9356', 'num_special': 934, 'spe_ratio': '0.9915'}\n",
      "| - {1: 1, 'size': 6136, 'sim': '0.9742', 'num_special': 0, 'spe_ratio': '0.0000'}\n",
      "| - {2: 2, 'size': 2922, 'sim': '0.9636', 'num_special': 66, 'spe_ratio': '0.0226'}\n",
      "====================epoch = 8====================\n",
      "| - {0: 0, 'size': 936, 'sim': '-0.8486', 'num_special': 930, 'spe_ratio': '0.9936'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here is an example of standard NN training + trajectory reweighting.\n",
    "\"\"\"\n",
    "\n",
    "# suppose there are training set and validation set, trajectory API initializaiton\n",
    "### currently, our API will take care of data part in training, see below\n",
    "api = API(x_train_tensor, \n",
    "          y_train_noisy_tensor, \n",
    "          x_valid_tensor, \n",
    "          y_valid_tensor, \n",
    "          num_cluster=3, \n",
    "          batch_size=100, \n",
    "          device=device, \n",
    "          iprint=2)\n",
    "\n",
    "# model and its paramters\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "L2 = 0.0005\n",
    "learning_rate = 0.001\n",
    "num_iter = 10\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=L2)\n",
    "\n",
    "# standard training starts\n",
    "epoch = 1\n",
    "while epoch <= num_iter:\n",
    "    print(\"=\"*20 + \"epoch = {}\".format(epoch) + \"=\"*20)\n",
    "    for step, (data, target, weight) in enumerate(api.train_loader): # api train_loader\n",
    "        data, target, weight = data.to(device), target.to(device), weight.to(device)\n",
    "        output = cnn(data)\n",
    "        loss = api.loss_func(output, target, weight) # api train_loader\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # record trajectory\n",
    "    api.createTrajectory(cnn)\n",
    "    \n",
    "    # cluster trajectory + reweight data\n",
    "    if epoch > 5:\n",
    "        api.clusterTrajectory() # run gmm cluster\n",
    "        api.reweightData(cnn, 2000, noise_index) # update train_loader\n",
    "        \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(list_1,list_2):\n",
    "    return sorted(list_1) == sorted(list_2)\n",
    "\n",
    "input = Variable(x_valid_tensor.cuda(), requires_grad = False);\n",
    "target = Variable(y_valid_tensor).cuda();\n",
    "\n",
    "cnn = CNN().cuda()\n",
    "predict = cnn(input);\n",
    "criterion = torch.nn.CrossEntropyLoss();\n",
    "loss = criterion(predict, target);\n",
    "loss.backward();\n",
    "temp1 = []\n",
    "for w in cnn.parameters():\n",
    "    if w.requires_grad:\n",
    "        temp1.extend(list(w.grad.cpu().detach().numpy().flatten()))\n",
    "\n",
    "cnn.zero_grad()\n",
    "\n",
    "predict = cnn(input);\n",
    "criterion = torch.nn.CrossEntropyLoss();\n",
    "loss = criterion(predict, target);\n",
    "loss.backward();\n",
    "temp2 = []\n",
    "for w in cnn.parameters():\n",
    "    if w.requires_grad:\n",
    "        temp2.extend(list(w.grad.cpu().detach().numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 - spatial.distance.cosine(temp1,temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.rand(1, 3, 224, 224).cuda(), requires_grad = True);\n",
    "target = Variable(torch.LongTensor([12])).cuda();\n",
    "\n",
    "net = torchvision.models.resnet18(pretrained = False).cuda();\n",
    "predict = net(input);\n",
    "criterion = torch.nn.CrossEntropyLoss();\n",
    "loss = criterion(predict, target);\n",
    "loss.backward();\n",
    "temp1 = []\n",
    "for w in net.parameters():\n",
    "    if w.requires_grad:\n",
    "        temp1.extend(list(w.grad.cpu().detach().numpy().flatten()))\n",
    "\n",
    "net.zero_grad()\n",
    "\n",
    "predict = net(input);\n",
    "criterion = torch.nn.CrossEntropyLoss();\n",
    "loss = criterion(predict, target);\n",
    "loss.backward();\n",
    "temp2 = []\n",
    "for w in net.parameters():\n",
    "    if w.requires_grad:\n",
    "        temp2.extend(list(w.grad.cpu().detach().numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 - spatial.distance.cosine(temp1,temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
